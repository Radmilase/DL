import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision import datasets
from torch.utils.data import DataLoader
from torchvision import models
import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device
print("устройство", device)
print("версия торч", torch.__version__)

import os

# # # Укажите путь к ZIP-архиву на вашем компьютере
# zip_path = "D:/Itmo/DL/veg.zip"  # Замените на ваш путь

# # Укажите путь для распаковки
# extract_path = "D:/Itmo/DLveg.zip"  # Замените на ваш путь

# # # Распакуйте архив
# with zipfile.ZipFile(zip_path, "r") as zip_ref:
#     zip_ref.extractall(extract_path)

# # Проверка содержимого распакованной папки
# print(os.listdir(extract_path))

# Укажите путь к данным
data_path = "D:/Itmo/DL/Vegetable_Images"
train_data_dir = "D:/Itmo/DL/Vegetable_Images/train"
test_data_dir = "D:/Itmo/DL/Vegetable_Images/test"
val_data_dir = "D:/Itmo/DL/Vegetable_Images/validation"

# Проверка содержимого папок
print("содержимое veg_img", os.listdir(data_path))
print("       ")
print("классы тренировочной выборки", os.listdir(train_data_dir))
print("       ")
print("классы тестовой выборки", os.listdir(test_data_dir))
print("       ")
print("классы валидационной выборки", os.listdir(val_data_dir))






import torchvision.datasets as datasets
from torchvision import datasets
from torchvision.datasets import ImageFolder

# Определим трансформации
train_transforms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
])

val_transforms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
])

test_transforms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
])


# Создадим датасеты
train_dataset = ImageFolder(train_data_dir, transform=train_transforms)
val_dataset = ImageFolder(val_data_dir, transform=val_transforms)
test_dataset = ImageFolder(test_data_dir, transform=test_transforms)

# Создадим датагенераторы
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

classes_list = train_dataset.classes
print(classes_list)

len(train_loader), len(val_loader), len(test_loader) #gjrfpsdftn количество батчей в даталодер
print("количество батчей в train", len(train_data_dir))
print("количество батчей в test", len(test_data_dir))
print("количество батчей в val", len(val_data_dir))


# загрузим предобученую архитектуру модели ResNet18
model = models.resnet18(pretrained=True)

# Заменим последний слой (fully connected) так, чтобы количество выходных каналов соответствовало 15 классам
num_classes = 15
model.fc = nn.Linear(model.fc.in_features, num_classes)


# from tqdm import tqdm

# # Переводит модель в режим оценки 
# model.eval() #Переводит модель в режим оценки 
# model.to(device)
# correct = 0
# total = 0
# with torch.no_grad():
#     for images, labels in tqdm(val_loader):
#         images, labels = images.to(device), labels.to(device)
#         outputs = model(images)
#         # print(outputs.shape)
#         _, predicted = outputs.max(1)
#         # print(predicted)
#         # print(labels)
#         total += labels.size(0)
#         correct += predicted.eq(labels).sum().item()
# val_accuracy = correct / total # Вычисляет точность модели 
# print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")


import matplotlib.pyplot as plt
import numpy as np
import random

def show_random_images(images, num_images=36):
    # Выбор случайных индексов для отображения изображений
    indices = random.sample(range(len(images)), min(num_images, len(images)))
    
    images = images.numpy().transpose((0, 2, 3, 1))
    
    fig, axes = plt.subplots(6, 6, figsize=(10, 10))
    
    for i in range(num_images):
        ax = axes[i // 6][i % 6] if num_images > i else None
        
        if ax is not None:
            ax.imshow(images[indices[i]])
            ax.axis('off')
            
        else:
            break
            
    plt.show()

# Получение первого батча из тренировочного загрузчика данных
images_batch = next(iter(train_loader))[0]

# Отображение случайных изображений из батча без нормализации цветов
show_random_images(images_batch)


# обучение сети
from tqdm import tqdm
# Определим функцию потерь и оптимизатор
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005)

# число эпох
num_epochs = 5

train_losses = []
train_accuracies = []
val_losses = []
val_accuracies = []
best_val_accuracy = 0
model.to(device)

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for images, labels in tqdm(train_loader):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    train_loss = running_loss / len(train_loader)
    train_accuracy = correct / total
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Валидация модели
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in tqdm(val_loader):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    val_loss /= len(val_loader)
    val_accuracy = correct / total
    val_losses.append(val_loss)
    val_accuracies.append(val_accuracy)

    print(f'Epoch [{epoch+1}/{num_epochs}], '
          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '
          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')

    # # Сохранение лучшей модели на основе валидационной точности
    # if val_accuracy > best_val_accuracy:
    #     best_val_accuracy = val_accuracy
    #     torch.save(model.state_dict(), 'best_model.pth')
    #     print('Saved best model!')

    # # Сохранение последней актуальной модели
    # torch.save(model.state_dict(), 'last_model.pth')
    # print()

print('Training and validation complete!')